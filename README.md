# Build with AG2 (formally AutoGen)
Getting started with AG2! Step-by-step guide, code samples, and application showcases to get you going with AG2

# About AG2

### Agents in AG2
We consider agents as digital assistants, each with a persona and capabilities. In AG2, they work together with other agents in [conversation patterns](https://ag2ai.github.io/ag2/docs/tutorial/conversation-patterns).

The `ConversableAgent` is the mainstay of AG2 agents and underpins other agent types.

Two other commonly used agents are the `AssistantAgent` (which has a task oriented system prompt) and `UserProxyAgent` (which is to represent you, a human, who provide inputs manually without an LLM).

Fundamental to AG2 is the ability to extend its core functionality, and this includes building agent types. These can be pre-built agents, examples being agents with memory, RAG, web surfing, and reasoning skills. Or, you can add capabilities, individually, to an existing `ConversableAgent`.

### Chats and Messages
AG2 agents will be having [conversations](https://ag2ai.github.io/ag2/docs/tutorial/conversation-patterns), or chats, and they will be working with a set of messages, passed around during the conversation.

To have a conversation, you'll initiate it, e.g. `initiate_chat`, and at the end of it you'll get a `ChatResult` that contains the messages and a summary.

Whether you're starting a one-on-one chat between agents, or a group chat with a hundred of them, you'll generally start them the same way, by initiating a chat between two agents.

### Human in the loop
As mentioned earlier, the `UserProxyAgent` can be used in place of a human and when it is their turn in the conversation, you'll be able to type in your response and the conversation will continue. [More info here](https://ag2ai.github.io/ag2/docs/tutorial/human-in-the-loop).

### LLMs
Core to AG2's agents are the ability to be underpinned by a number of LLMs. Passing in an LLM configuration enables your agent to use one or more LLMs, in a priority order. A whole range of LLM providers are available, both cloud-based and local (OpenAI, Google, Amazon, Anthropic, Togther.AI, Mistral, Ollama). [LLM Configuration info here](https://ag2ai.github.io/ag2/docs/topics/llm_configuration), and [non-OpenAI provider info here](https://ag2ai.github.io/ag2/docs/topics/non-openai-models/about-using-nonopenai-models).

### Code execution
You need to run code generated by an LLM? No problem, there are a number of methods to do so, [more info here](https://ag2ai.github.io/ag2/docs/tutorial/code-executors).

### Ending a chat
How a chat ends depends on the conversation pattern, [here is some guidance](https://ag2ai.github.io/ag2/docs/tutorial/chat-termination).

Examples of ways to end a chat include setting a maximum number of replies/turns/rounds, looking for a keyword in an agent's response, a human entering an exit keyword, or a hand off in a swarm.


# Let's try it

Get AG2 installed:
```bash
pip install ag2
```
We'll use OpenAI's LLMs for these examples, so put your key into an environment variable called `OPENAI_API_KEY`.
### Talking to an agent
Here are two agents that will chat with each other. One represents you, and one is your typical AI assistant that answers whatever you ask of it.

```python
import os
from autogen import UserProxyAgent, AssistantAgent

llm_config = {"model": "gpt-4o-mini", "api_key": os.environ["OPENAI_API_KEY"]}
assistant = AssistantAgent("assistant", llm_config=llm_config)
human = UserProxyAgent("human", code_execution_config=False)

# We start the chat from the UserProxyAgent, representing you, and ask the
# AssistantAgent your question.
chat_result = human.initiate_chat(
    assistant,
    message="In short, what's the big deal about AI?",
)
```
```bash
[OUTPUT HERE]
```
You can continue to interact with assistant agent through your console, type `exit` to end the chat.

### Two-way chat
These two funny agents will chat with each other and they're both powered by an LLM.

We give them their persona and instructions by setting their system message.

To make sure they don't talk forever, we're going to instruct one to say the keyword 'HILARIOUS' to end the chat. Then, we set the other agent's `is_termination_msg` to a lambda function to look for that keyword in the messages they receive.

```python
import os
from autogen import ConversableAgent

llm_config = {"model": "gpt-4o-mini", "api_key": os.environ["OPENAI_API_KEY"]}

emma = ConversableAgent(
    "Emma",
    llm_config=llm_config,
    system_message="Your name is Emma and you are a comedian in two-person comedy show. Say the word HILARIOUS once you've heard a joke from Jack.",
)

jack = ConversableAgent(
    "Jack",
    llm_config=llm_config,
    system_message="Your name is Jack and you are a comedian in a two-person comedy show.",
    is_termination_msg=lambda msg: "hilarious" in msg["content"].lower(), # Ends the chat if it exists
)

chat_result = emma.initiate_chat(
    jack,
    message="Jack, tell me a joke about goldfish and peanut butter.",
)
```
All being well, Emma will ask Jack to tell her a joke, Jack will then respond to Emma with a joke, Emma will say it was 'HILARIOUS', and, finally, Jack will check for that keyword and end the chat.

**UP TO HERE**


## :notebook_with_decorative_cover: Cookbook
Looking for a way to create group chats, sequential chats, nested chats, RAG agents, etc., check out these cookbooks that will get you started.

[Cookbooks](https://ag2ai.github.io/ag2/docs/notebooks)

## :stars: Samples
Need some inspiration or interested in what AutoGen can do? Check out applications that use AG2.

- [AutoGen Studio](samples/apps/autogen-studio/) - low-code toolkit for building AI agents and prototype AG2 workflows.
- [AutoAnny](samples/apps/auto-anny/) - Discord bot built using AG2 to help with AutoGen's Discord server.
- [CAP](samples/apps/cap/) - Extends AG2 to allows Agents to communicate via a message bus. A message based, actor platform that allows actors to be composed into arbitrary graphs.
- [Promptflow](samples/apps/promptflow-autogen/) - Comprehensive suite of tools that simplifies the development, testing, evaluation, and deployment of LLM based AI applications.
- [FastAPI](samples/apps/websockets/) - Using websockets with FastAPI and AG2.

## :wrench: Tools
- [AutoGen Bench](samples/tools/autogenbench/) - A tool for repeatedly running a set of pre-defined AG2 tasks in a setting with tightly-controlled initial conditions.
- [Fine-tuning](samples/tools/finetuning/) - Tools to fine-tune local models.
- [WebArena Benchmark](samples/tools/webarena/) - Running AG2 agents on WebArena.

## :city_sunset: Gallery
Demonstrations, code, and videos of applications built with AG2.

[Gallery](https://ag2ai.github.io/ag2/docs/Gallery)

## Contributing
Created something with AG2? We'd ðŸ’™ to share it with the community, please create a PR here or contact us at auto-gen@outlook.com.
